{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">ALGORYTM DETEKCJI NOWOTWORU SKÓRY</h1>\n",
    "<h3 align=\"center\">Etap 1 - wykrywanie krawędzi zmiany</h3>\n",
    "<br>\n",
    "<p>Serwis dostępny na: [melanoma.tk](http://melanoma.tk)</p>\n",
    "<br>    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import random\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagePath = os.getcwd() + '/uploads/'\n",
    "histogramPath = os.getcwd() + '/static/histograms/'\n",
    "filename = \"melanomaCancer.jpg\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">Krok 0: Pobranie od użytkownika obrazu</h1>\n",
    "<br>\n",
    "<p>Użytkownik \"uploaduje\" obraz swojej zmiany skóry:</p> \n",
    "<br>\n",
    "<img src=\"static/melanomaCancer.jpg\" align=\"center\" width=50%>\n",
    "<br>\n",
    "<p>Celem algorytmu jest to aby po przetworzeniu obrazu zwrócił prawdopodobieństwo, z jakim ta zmiana jest nowotworem.</p>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1 read convert to grayscale image\n",
    "img = cv2.imread(imagePath + filename, cv2.IMREAD_GRAYSCALE)\n",
    "# save result\n",
    "cv2.imwrite(histogramPath + \"0Started.jpg\", img, [int(cv2.IMWRITE_JPEG_QUALITY), 95])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">Krok 1: Wczytanie obrazu i konwersja do skali szarości</h1>\n",
    "<br>\n",
    "<img src=\"static/histograms/0Started.jpg\" width=50%>\n",
    "<br>\n",
    "<p>Obraz jest wczytywany przy pomocy metody imread() z biblioteki opencv (cv2) z parametrem IMREAD_GRAYSCALE co oznacza konwersję wczytanego kolorowego obrazu do obrazu w skali szarości.</p>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 2: Gaussian filter\n",
    "denoised = cv2.GaussianBlur(img, (5, 5), 0)\n",
    "# save result\n",
    "cv2.imwrite(histogramPath + \"1denoised.jpg\", denoised, [int(cv2.IMWRITE_JPEG_QUALITY), 95])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">Krok 2: Filtr Gaussa</h1>\n",
    "<br>\n",
    "<img src=\"static/histograms/1denoised.jpg\" width=50%>\n",
    "<br>\n",
    "<p>Obraz jest wygładzany przy pomocy dolnoprzepustowego filtru Gaussa.</p>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Step 3: Thresholding\n",
    "ret, thresh2 = cv2.threshold(denoised, 127, 255, cv2.THRESH_BINARY_INV)\n",
    "# save result\n",
    "cv2.imwrite(histogramPath + \"2Tresh.jpg\", thresh2, [int(cv2.IMWRITE_JPEG_QUALITY), 95])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">Krok 3: Thresholding - binaryzacja</h1>\n",
    "<br>\n",
    "<img src=\"static/histograms/2Tresh.jpg\" width=50%>\n",
    "<br>\n",
    "<p>Obraz jest poddawany binaryzacji z progiem 127 powyżej, którego pixelom przypisywana jest wartość 0, a poniżej wartość 1.\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "denoisedTresh = cv2.GaussianBlur(thresh2, (5, 5), 0)\n",
    "# save result\n",
    "cv2.imwrite(histogramPath + \"3denoisedThresh.jpg\", denoisedTresh, [int(cv2.IMWRITE_JPEG_QUALITY), 95])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">Krok 4: Filtr Gaussa</h1>\n",
    "<br>\n",
    "<img src=\"static/histograms/3denoisedThresh.jpg\" width=50%>\n",
    "<br>\n",
    "<p>Zbinaryzowany obraz jest poddawany kolejnej filtracji Gaussa w celu wygładzenia krawędzi \"dziór\", które będą w następnym kroku wypełniane.</p>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "flood_fill = denoisedTresh.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(351992, array([[255, 255, 255, ..., 255, 255, 255],\n",
       "        [255, 255, 255, ..., 255, 255, 255],\n",
       "        [255, 255, 255, ..., 255, 255, 255],\n",
       "        ...,\n",
       "        [255, 255, 255, ..., 255, 255, 255],\n",
       "        [255, 255, 255, ..., 255, 255, 255],\n",
       "        [255, 255, 255, ..., 255, 255, 255]], dtype=uint8), array([[1, 1, 1, ..., 1, 1, 1],\n",
       "        [1, 1, 1, ..., 1, 1, 1],\n",
       "        [1, 1, 1, ..., 1, 1, 1],\n",
       "        ...,\n",
       "        [1, 1, 1, ..., 1, 1, 1],\n",
       "        [1, 1, 1, ..., 1, 1, 1],\n",
       "        [1, 1, 1, ..., 1, 1, 1]], dtype=uint8), (0, 0, 920, 613))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h, w = denoisedTresh.shape[:2]\n",
    "mask = np.zeros((h + 2, w + 2), np.uint8)\n",
    "\n",
    "# Step 5: Floodfill from point (0, 0)\n",
    "cv2.floodFill(flood_fill, mask, (0, 0), 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Invert floodfilled image\n",
    "flood_fill_inv = cv2.bitwise_not(flood_fill)\n",
    "# save result\n",
    "cv2.imwrite(histogramPath + \"5invOut.jpg\", flood_fill_inv, [int(cv2.IMWRITE_JPEG_QUALITY), 95])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">Krok 5: Wytworzenie maski</h1>\n",
    "<br>\n",
    "<img src=\"static/histograms/5invOut.jpg\" width=50%>\n",
    "<br>\n",
    "<p>Wytworzenie maski czarnych dziór wewnątrz obiektu zmiany, która w następnej operacji logicznej wypełni cały obszar zmiany.</p>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine the two images to get the foreground.\n",
    "filled_out = denoisedTresh | flood_fill_inv\n",
    "# save result\n",
    "cv2.imwrite(histogramPath + \"6Out.jpg\", filled_out, [int(cv2.IMWRITE_JPEG_QUALITY), 95])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">Krok 6: Wypełnienie obszaru zmiany</h1>\n",
    "<br>\n",
    "<img src=\"static/histograms/6Out.jpg\" width=50%>\n",
    "<br>\n",
    "<p>Obraz po operacji OR na masce i obrazie z kroku 4 jest już zmianą która w całości jest wypełniona, dzoęki czemu możemy teraz łatwo wykryć krawędzie.</p>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 6: Detect edges - Laplacian\n",
    "filter2 = cv2.Laplacian(filled_out, cv2.CV_64F)\n",
    "# save result\n",
    "cv2.imwrite(histogramPath + \"7detectedEdges.jpg\", filter2, [int(cv2.IMWRITE_JPEG_QUALITY), 95]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](\"histograms/7detectedEdges.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">Krok 7: Laplacjan</h1>\n",
    "<br>\n",
    "<img src=\"static/histograms/7detectedEdges.jpg\" width=50%>\n",
    "<br>\n",
    "<p>Wykonanie wyostrzania Laplacjanu pozwoliło na eleganckie wyznaczenie krawędzi zmiany skórnej, co jest bardzo ważne do dalszych kroków wyliczania prawdopodobieństwa nowotworowości zmiany opartych na symetri i regularności zmiany skórnej.</p>\n",
    "<br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
